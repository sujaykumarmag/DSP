{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ArgumentParser in module argparse:\n",
      "\n",
      "class ArgumentParser(_AttributeHolder, _ActionsContainer)\n",
      " |  ArgumentParser(prog=None, usage=None, description=None, epilog=None, parents=[], formatter_class=<class 'argparse.HelpFormatter'>, prefix_chars='-', fromfile_prefix_chars=None, argument_default=None, conflict_handler='error', add_help=True, allow_abbrev=True, exit_on_error=True)\n",
      " |  \n",
      " |  Object for parsing command line strings into Python objects.\n",
      " |  \n",
      " |  Keyword Arguments:\n",
      " |      - prog -- The name of the program (default:\n",
      " |          ``os.path.basename(sys.argv[0])``)\n",
      " |      - usage -- A usage message (default: auto-generated from arguments)\n",
      " |      - description -- A description of what the program does\n",
      " |      - epilog -- Text following the argument descriptions\n",
      " |      - parents -- Parsers whose arguments should be copied into this one\n",
      " |      - formatter_class -- HelpFormatter class for printing help messages\n",
      " |      - prefix_chars -- Characters that prefix optional arguments\n",
      " |      - fromfile_prefix_chars -- Characters that prefix files containing\n",
      " |          additional arguments\n",
      " |      - argument_default -- The default value for all arguments\n",
      " |      - conflict_handler -- String indicating how to handle conflicts\n",
      " |      - add_help -- Add a -h/-help option\n",
      " |      - allow_abbrev -- Allow long options to be abbreviated unambiguously\n",
      " |      - exit_on_error -- Determines whether or not ArgumentParser exits with\n",
      " |          error info when an error occurs\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ArgumentParser\n",
      " |      _AttributeHolder\n",
      " |      _ActionsContainer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, prog=None, usage=None, description=None, epilog=None, parents=[], formatter_class=<class 'argparse.HelpFormatter'>, prefix_chars='-', fromfile_prefix_chars=None, argument_default=None, conflict_handler='error', add_help=True, allow_abbrev=True, exit_on_error=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  add_subparsers(self, **kwargs)\n",
      " |      # ==================================\n",
      " |      # Optional/Positional adding methods\n",
      " |      # ==================================\n",
      " |  \n",
      " |  convert_arg_line_to_args(self, arg_line)\n",
      " |  \n",
      " |  error(self, message)\n",
      " |      error(message: string)\n",
      " |      \n",
      " |      Prints a usage message incorporating the message to stderr and\n",
      " |      exits.\n",
      " |      \n",
      " |      If you override this in a subclass, it should not return -- it\n",
      " |      should either exit or raise an exception.\n",
      " |  \n",
      " |  exit(self, status=0, message=None)\n",
      " |      # ===============\n",
      " |      # Exiting methods\n",
      " |      # ===============\n",
      " |  \n",
      " |  format_help(self)\n",
      " |  \n",
      " |  format_usage(self)\n",
      " |      # =======================\n",
      " |      # Help-formatting methods\n",
      " |      # =======================\n",
      " |  \n",
      " |  parse_args(self, args=None, namespace=None)\n",
      " |      # =====================================\n",
      " |      # Command line argument parsing methods\n",
      " |      # =====================================\n",
      " |  \n",
      " |  parse_intermixed_args(self, args=None, namespace=None)\n",
      " |  \n",
      " |  parse_known_args(self, args=None, namespace=None)\n",
      " |  \n",
      " |  parse_known_intermixed_args(self, args=None, namespace=None)\n",
      " |  \n",
      " |  print_help(self, file=None)\n",
      " |  \n",
      " |  print_usage(self, file=None)\n",
      " |      # =====================\n",
      " |      # Help-printing methods\n",
      " |      # =====================\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _AttributeHolder:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _AttributeHolder:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _ActionsContainer:\n",
      " |  \n",
      " |  add_argument(self, *args, **kwargs)\n",
      " |      add_argument(dest, ..., name=value, ...)\n",
      " |      add_argument(option_string, option_string, ..., name=value, ...)\n",
      " |  \n",
      " |  add_argument_group(self, *args, **kwargs)\n",
      " |  \n",
      " |  add_mutually_exclusive_group(self, **kwargs)\n",
      " |  \n",
      " |  get_default(self, dest)\n",
      " |  \n",
      " |  register(self, registry_name, value, object)\n",
      " |      # ====================\n",
      " |      # Registration methods\n",
      " |      # ====================\n",
      " |  \n",
      " |  set_defaults(self, **kwargs)\n",
      " |      # ==================================\n",
      " |      # Namespace default accessor methods\n",
      " |      # ==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(argparse.ArgumentParser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m      8\u001b[0m drug_set \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mget_drug_features()\n\u001b[1;32m      9\u001b[0m triplets \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mget_labeled_triples()\n\u001b[1;32m     12\u001b[0m generator \u001b[38;5;241m=\u001b[39m BatchGenerator(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,context_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, drug_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,drug_molecules\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m---> 13\u001b[0m                            context_feature_set\u001b[38;5;241m=\u001b[39mcontext_set, drug_feature_set\u001b[38;5;241m=\u001b[39mdrug_set, labeled_triples\u001b[38;5;241m=\u001b[39m\u001b[43mtrain\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "from chemicalx.data import DrugPairBatch, BatchGenerator, DrugCombDB\n",
    "\n",
    "loader = DrugCombDB()\n",
    "\n",
    "\n",
    "\n",
    "context_set = loader.get_context_features()\n",
    "drug_set = loader.get_drug_features()\n",
    "triplets = loader.get_labeled_triples()\n",
    "\n",
    "\n",
    "generator = BatchGenerator(batch_size=32,context_features=True, drug_features=True,drug_molecules=True,\n",
    "                           context_feature_set=context_set, drug_feature_set=drug_set, labeled_triples=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'DrugCombDB' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'DrugCombDB' has no len()"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191391"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2956"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(drug_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from  chemicalx.data import BatchGenerator, DrugComb, DrugCombDB, OncoPolyPharmacology\n",
    "from chemicalx.data import DrugPairBatch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "    Stratified KFold should be subclassed from `chemicalx` package\n",
    "'''\n",
    "\n",
    "\n",
    "class DataLoader(BatchGenerator):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # self.model = args.model\n",
    "        self.dataset = \"drugcomb\"\n",
    "        # self.compute_embeddings = args.compute_embeddings\n",
    "        # self.validation = args.validation\n",
    "        drug_set, context_set, train, self.test = self.get_datasets()\n",
    "        super(DataLoader,self).__init__(batch_size=32,context_features=True, drug_features=True,drug_molecules=True,\n",
    "                           context_feature_set=context_set, drug_feature_set=drug_set, labeled_triples=train)\n",
    "        \n",
    "    \n",
    "    def get_datasets(self):\n",
    "        if self.dataset == \"drugcomb\":\n",
    "            loader = DrugComb()\n",
    "        elif self.dataset == \"drucombdb\":\n",
    "            loader = DrugCombDB()\n",
    "        elif self.dataset == \"oncolypharma\":\n",
    "            loader = OncoPolyPharmacology()\n",
    "        else:\n",
    "            print(f\"The given dataset {self.dataset} is not a part of chemicalx, provide the 3 synergy prediction tasks\")\n",
    "\n",
    "        drug_set = loader.get_drug_features()\n",
    "        context_set = loader.get_context_features()\n",
    "        triplets = loader.get_labeled_triples()\n",
    "        train, test = triplets.train_test_split(train_size=0.8)\n",
    "        return drug_set, context_set, train, test\n",
    "    \n",
    "\n",
    "    def get_testloader(self):\n",
    "        self.labeled_triples = self.test\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DrugPairBatch(identifiers=          drug_1    drug_2     context  label\n",
      "532891  24776445  54676905  LB2518-MEL    0.0\n",
      "54546     132971      5790     HS 578T    0.0\n",
      "551638  16124726   9943465     RVH-421    1.0\n",
      "306501    104842    163659    NCI-H522    1.0\n",
      "622179  11977753  25022668     CBRC008    0.0\n",
      "24815   54611422      3685      SNB-19    1.0\n",
      "405789   5329102      5799         M14    1.0\n",
      "491679  11640390    644213       A101D    0.0\n",
      "501594   3463933   5278396    COLO 800    0.0\n",
      "279629  24958200   3062316    NCIH1650    1.0, drug_features_left=tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]]), drug_molecules_left=PackedGraph(batch_size=10, num_nodes=[27, 26, 32, 29, 36, 34, 29, 32, 22, 24], num_edges=[58, 60, 72, 66, 82, 72, 62, 74, 46, 54], num_relation=4), drug_features_right=tensor([[0., 0., 1.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 2.]]), drug_molecules_right=PackedGraph(batch_size=10, num_nodes=[17, 17, 21, 76, 29, 36, 15, 19, 27, 33], num_edges=[34, 36, 48, 166, 66, 80, 36, 40, 62, 72], num_relation=4), context_features=tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), labels=tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]))\n"
     ]
    }
   ],
   "source": [
    "for i in x:\n",
    "    sample = i\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drugs</th>\n",
       "      <th>Drug Embeddings</th>\n",
       "      <th>mrr</th>\n",
       "      <th>hits@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['65628']</td>\n",
       "      <td>[-9.71540355682373, -11.125833511352539, -7.97...</td>\n",
       "      <td>0.363178</td>\n",
       "      <td>0.854167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['39562']</td>\n",
       "      <td>[-9.794931411743164, -8.03378963470459, -12.02...</td>\n",
       "      <td>0.292606</td>\n",
       "      <td>0.706522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['216326']</td>\n",
       "      <td>[-8.874168395996094, -4.353018760681152, 2.002...</td>\n",
       "      <td>0.417559</td>\n",
       "      <td>0.988095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['20279']</td>\n",
       "      <td>[0.9404932856559753, -6.391180515289307, -0.40...</td>\n",
       "      <td>0.416144</td>\n",
       "      <td>0.964286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['439693']</td>\n",
       "      <td>[1.144148349761963, -6.067200183868408, 0.0682...</td>\n",
       "      <td>0.362388</td>\n",
       "      <td>0.964286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>['24197464']</td>\n",
       "      <td>[1.0625643730163574, -6.0400519371032715, -0.3...</td>\n",
       "      <td>0.368407</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2952</th>\n",
       "      <td>['54611422']</td>\n",
       "      <td>[2.236278772354126, -5.427398681640625, 1.5881...</td>\n",
       "      <td>0.345175</td>\n",
       "      <td>0.979167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2953</th>\n",
       "      <td>['441203']</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2954</th>\n",
       "      <td>['54611489']</td>\n",
       "      <td>[3.107060432434082, -5.344871520996094, 0.7818...</td>\n",
       "      <td>0.337139</td>\n",
       "      <td>0.988281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2955</th>\n",
       "      <td>['3685']</td>\n",
       "      <td>[-3.593794107437134, -9.204462051391602, -1.82...</td>\n",
       "      <td>0.290498</td>\n",
       "      <td>0.987500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2956 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Drugs                                    Drug Embeddings  \\\n",
       "0        ['65628']  [-9.71540355682373, -11.125833511352539, -7.97...   \n",
       "1        ['39562']  [-9.794931411743164, -8.03378963470459, -12.02...   \n",
       "2       ['216326']  [-8.874168395996094, -4.353018760681152, 2.002...   \n",
       "3        ['20279']  [0.9404932856559753, -6.391180515289307, -0.40...   \n",
       "4       ['439693']  [1.144148349761963, -6.067200183868408, 0.0682...   \n",
       "...            ...                                                ...   \n",
       "2951  ['24197464']  [1.0625643730163574, -6.0400519371032715, -0.3...   \n",
       "2952  ['54611422']  [2.236278772354126, -5.427398681640625, 1.5881...   \n",
       "2953    ['441203']  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2954  ['54611489']  [3.107060432434082, -5.344871520996094, 0.7818...   \n",
       "2955      ['3685']  [-3.593794107437134, -9.204462051391602, -1.82...   \n",
       "\n",
       "           mrr   hits@10  \n",
       "0     0.363178  0.854167  \n",
       "1     0.292606  0.706522  \n",
       "2     0.417559  0.988095  \n",
       "3     0.416144  0.964286  \n",
       "4     0.362388  0.964286  \n",
       "...        ...       ...  \n",
       "2951  0.368407  0.961538  \n",
       "2952  0.345175  0.979167  \n",
       "2953  0.000000  0.000000  \n",
       "2954  0.337139  0.988281  \n",
       "2955  0.290498  0.987500  \n",
       "\n",
       "[2956 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"../datasets/embeddings_drugcombdb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchdrug.data\n",
    "from torch.types import Device\n",
    "from src.utils import plot_embeddings\n",
    "\n",
    "__all__ = [\n",
    "    \"PackedGraph\",\n",
    "    \"Graph\",\n",
    "]\n",
    "\n",
    "class PackedGraph(torchdrug.data.PackedGraph):\n",
    "    def to(self, device: Device):\n",
    "        if isinstance(device, str):\n",
    "            if device == \"cpu\":\n",
    "                return self.cpu()\n",
    "            elif device == \"cuda\":\n",
    "                return self.cuda()\n",
    "            else:\n",
    "                raise NotImplementedError(f\"{self.__class__.__name__}.to() is not implemented for string: {device}\")\n",
    "        elif isinstance(device, torch.device):\n",
    "            if device.type == \"cpu\":\n",
    "                return self.cpu()\n",
    "            elif device.type == \"cuda\":\n",
    "                return self.cuda()\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "        else:\n",
    "            raise TypeError\n",
    "\n",
    "\n",
    "class Graph(torchdrug.data.Graph):\n",
    "    packed_type = PackedGraph\n",
    "\n",
    "\n",
    "\n",
    "from typing import List, Optional\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.functional import normalize\n",
    "from torchdrug.layers import MaxReadout\n",
    "from torchdrug.layers import MultiLayerPerceptron as MLP\n",
    "from torchdrug.models import GraphConvolutionalNetwork, GraphAttentionNetwork, GraphIsomorphismNetwork\n",
    "\n",
    "# from compat import PackedGraph\n",
    "from chemicalx.constants import TORCHDRUG_NODE_FEATURES\n",
    "from chemicalx.data import DrugPairBatch\n",
    "from chemicalx.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemicalx.data import DrugPairBatch, BatchGenerator, DrugCombDB\n",
    "\n",
    "loader = DrugCombDB()\n",
    "\n",
    "\n",
    "\n",
    "context_set = loader.get_context_features()\n",
    "drug_set = loader.get_drug_features()\n",
    "triplets = loader.get_labeled_triples()\n",
    "\n",
    "train, test = triplets.train_test_split(train_size=0.8)\n",
    "\n",
    "loader = BatchGenerator(batch_size=32,context_features=True, drug_features=True,drug_molecules=True,\n",
    "                           context_feature_set=context_set, drug_feature_set=drug_set, labeled_triples=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loader.context_feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 2.],\n",
       "        [0., 5., 0.,  ..., 4., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 2., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.drug_features_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sample.drug_molecules_left:\n",
    "    sample1 = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'__name__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msample1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__name__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: '__name__'"
     ]
    }
   ],
   "source": [
    "sample1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on dict object:\n",
      "\n",
      "class dict(object)\n",
      " |  dict() -> new empty dictionary\n",
      " |  dict(mapping) -> new dictionary initialized from a mapping object's\n",
      " |      (key, value) pairs\n",
      " |  dict(iterable) -> new dictionary initialized as if via:\n",
      " |      d = {}\n",
      " |      for k, v in iterable:\n",
      " |          d[k] = v\n",
      " |  dict(**kwargs) -> new dictionary initialized with the name=value pairs\n",
      " |      in the keyword argument list.  For example:  dict(one=1, two=2)\n",
      " |  \n",
      " |  Built-in subclasses:\n",
      " |      StgDict\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __contains__(self, key, /)\n",
      " |      True if the dictionary has the specified key, else False.\n",
      " |  \n",
      " |  __delitem__(self, key, /)\n",
      " |      Delete self[key].\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __getitem__(...)\n",
      " |      x.__getitem__(y) <==> x[y]\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __ior__(self, value, /)\n",
      " |      Return self|=value.\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __or__(self, value, /)\n",
      " |      Return self|value.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __reversed__(self, /)\n",
      " |      Return a reverse iterator over the dict keys.\n",
      " |  \n",
      " |  __ror__(self, value, /)\n",
      " |      Return value|self.\n",
      " |  \n",
      " |  __setitem__(self, key, value, /)\n",
      " |      Set self[key] to value.\n",
      " |  \n",
      " |  __sizeof__(...)\n",
      " |      D.__sizeof__() -> size of D in memory, in bytes\n",
      " |  \n",
      " |  clear(...)\n",
      " |      D.clear() -> None.  Remove all items from D.\n",
      " |  \n",
      " |  copy(...)\n",
      " |      D.copy() -> a shallow copy of D\n",
      " |  \n",
      " |  get(self, key, default=None, /)\n",
      " |      Return the value for key if key is in the dictionary, else default.\n",
      " |  \n",
      " |  items(...)\n",
      " |      D.items() -> a set-like object providing a view on D's items\n",
      " |  \n",
      " |  keys(...)\n",
      " |      D.keys() -> a set-like object providing a view on D's keys\n",
      " |  \n",
      " |  pop(...)\n",
      " |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      " |      \n",
      " |      If the key is not found, return the default if given; otherwise,\n",
      " |      raise a KeyError.\n",
      " |  \n",
      " |  popitem(self, /)\n",
      " |      Remove and return a (key, value) pair as a 2-tuple.\n",
      " |      \n",
      " |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      " |      Raises KeyError if the dict is empty.\n",
      " |  \n",
      " |  setdefault(self, key, default=None, /)\n",
      " |      Insert key with a value of default if key is not in the dictionary.\n",
      " |      \n",
      " |      Return the value for key if key is in the dictionary, else default.\n",
      " |  \n",
      " |  update(...)\n",
      " |      D.update([E, ]**F) -> None.  Update D from dict/iterable E and F.\n",
      " |      If E is present and has a .keys() method, then does:  for k in E: D[k] = E[k]\n",
      " |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      " |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      " |  \n",
      " |  values(...)\n",
      " |      D.values() -> an object providing a view on D's values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  __class_getitem__(...) from builtins.type\n",
      " |      See PEP 585\n",
      " |  \n",
      " |  fromkeys(iterable, value=None, /) from builtins.type\n",
      " |      Create a new dictionary with keys from iterable and values set to value.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __hash__ = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sample1.data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug_1</th>\n",
       "      <th>drug_2</th>\n",
       "      <th>context</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147626</th>\n",
       "      <td>123631</td>\n",
       "      <td>457193</td>\n",
       "      <td>ACHN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40359</th>\n",
       "      <td>447043</td>\n",
       "      <td>115355</td>\n",
       "      <td>KBM-7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74212</th>\n",
       "      <td>36314</td>\n",
       "      <td>123608</td>\n",
       "      <td>HT29</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185454</th>\n",
       "      <td>54600319</td>\n",
       "      <td>32874</td>\n",
       "      <td>RPMI-8226</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57367</th>\n",
       "      <td>667490</td>\n",
       "      <td>6445540</td>\n",
       "      <td>LOX IMVI</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119879</th>\n",
       "      <td>2708</td>\n",
       "      <td>387447</td>\n",
       "      <td>MCF7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103694</th>\n",
       "      <td>4114</td>\n",
       "      <td>545</td>\n",
       "      <td>IGROV1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>25126798</td>\n",
       "      <td>3367</td>\n",
       "      <td>CCRF-CEM</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146867</th>\n",
       "      <td>25136944</td>\n",
       "      <td>457193</td>\n",
       "      <td>SK-MEL-2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>3385</td>\n",
       "      <td>6252</td>\n",
       "      <td>ACHN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153112 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          drug_1   drug_2    context  label\n",
       "147626    123631   457193       ACHN    1.0\n",
       "40359     447043   115355      KBM-7    1.0\n",
       "74212      36314   123608       HT29    0.0\n",
       "185454  54600319    32874  RPMI-8226    1.0\n",
       "57367     667490  6445540   LOX IMVI    0.0\n",
       "...          ...      ...        ...    ...\n",
       "119879      2708   387447       MCF7    0.0\n",
       "103694      4114      545     IGROV1    0.0\n",
       "131932  25126798     3367   CCRF-CEM    0.0\n",
       "146867  25136944   457193   SK-MEL-2    1.0\n",
       "121958      3385     6252       ACHN    1.0\n",
       "\n",
       "[153112 rows x 4 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for i in loader:\n",
    "    x = x+1\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "from ultra.datasets import HM\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from ultra.tasks import build_relation_graph\n",
    "from collections import UserDict\n",
    "from typing import Dict, Iterable, Mapping, Union\n",
    "from chemicalx.data import DrugCombDB, BatchGenerator, DrugComb, OncoPolyPharmacology\n",
    "import torch\n",
    "from torchdrug.data import Molecule,PackedGraph,Graph\n",
    "import math\n",
    "import torch\n",
    "from torch import distributed as dist\n",
    "from torch.utils import data as torch_data\n",
    "from torch_geometric.data import Data\n",
    "from ultra import tasks, util\n",
    "from torch_geometric.data import Data, InMemoryDataset, download_url, extract_zip\n",
    "import os\n",
    "from ultra.tasks import build_relation_graph\n",
    "import pandas as pd\n",
    "from molecule import MoleculesData\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import utils as mu\n",
    "import numpy as np \n",
    "import gc\n",
    "import psutil\n",
    "\n",
    "\n",
    "\n",
    "model = AutoModel.from_pretrained(\"mgalkin/ultra_3g\", trust_remote_code=True)\n",
    "\n",
    "loader = DrugCombDB()\n",
    "\n",
    "context_set = loader.get_context_features()\n",
    "drug_set = loader.get_drug_features()\n",
    "triplets = loader.get_labeled_triples()\n",
    "\n",
    "train, test = triplets.train_test_split(train_size=0.8)\n",
    "\n",
    "\n",
    "def log_memory_usage(step):\n",
    "    process = psutil.Process()\n",
    "    memory_info = process.memory_info()\n",
    "    # print(f\"[{step}] Memory usage: {memory_info.rss / 1024 ** 2:.2f} MB\")\n",
    "\n",
    "                           \n",
    "def all_negative(data, batch):\n",
    "    pos_h_index, pos_t_index, pos_r_index = batch\n",
    "    r_index = pos_r_index.unsqueeze(-1).expand(-1, data.num_nodes)\n",
    "    # generate all negative tails for this batch\n",
    "    all_index = torch.arange(data.num_nodes)\n",
    "    h_index, t_index = torch.meshgrid(pos_h_index, all_index, indexing=\"ij\")  # indexing \"xy\" would return transposed\n",
    "    t_batch = torch.stack([h_index, t_index, r_index], dim=-1)\n",
    "    # generate all negative heads for this batch\n",
    "    all_index = torch.arange(data.num_nodes)\n",
    "    t_index, h_index = torch.meshgrid(pos_t_index, all_index, indexing=\"ij\")\n",
    "    h_batch = torch.stack([h_index, t_index, r_index], dim=-1)\n",
    "\n",
    "    return t_batch, h_batch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_edge_lists(edge_lists_save,i):\n",
    "    with open(f\"datasets_edges/test{str(i)}.txt\", 'w') as file:\n",
    "        for edge in edge_lists_save:\n",
    "            file.write('\\t'.join(map(str, edge)) + '\\n')\n",
    "\n",
    "def save_edges(edge_lists_save):\n",
    "    with open(f\"test.txt\", 'w') as file:\n",
    "        for edge in edge_lists_save:\n",
    "            file.write('\\t'.join(map(str, edge)) + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "drug_embeddings = []\n",
    "drugs = []\n",
    "mrr = []\n",
    "hits10 = []\n",
    "for ind,i in tqdm(enumerate(drug_set)):\n",
    "    edge_lists = []\n",
    "    x = Graph.pack([drug_set[i][\"molecule\"]])\n",
    "\n",
    "    for j in x.edge_list.cpu().numpy().tolist():\n",
    "        x1 = [j[0],j[2],j[1]]\n",
    "        edge_lists.append(j)\n",
    "    \n",
    "\n",
    "    # save_edge_lists(edge_lists,ind)  \n",
    "    # save_edges(edge_lists)\n",
    "    embeddings  = []\n",
    "  \n",
    "    md = MoleculesData()\n",
    "    data = md.process()\n",
    "    device = util.get_devices(None)\n",
    "    world_size = util.get_world_size()\n",
    "    rank = util.get_rank()\n",
    "    sampler = torch_data.DistributedSampler(edge_lists, world_size, rank)\n",
    "    test_loader = torch_data.DataLoader(edge_lists, len(edge_lists), sampler=sampler)    \n",
    "    model.eval()\n",
    "    \n",
    "    try:\n",
    "        res = mu.test(model,data,edge_lists)\n",
    "        mrr.append(res[0].cpu().item())\n",
    "        hits10.append(res[1].cpu().item())\n",
    "\n",
    "    except:\n",
    "        mrr.append(0)\n",
    "        hits10.append(0)\n",
    "        print(f\"Wrong in Dataloader\")\n",
    "    \n",
    "    for batch in test_loader:\n",
    "        t_batch, h_batch = all_negative(data, batch)\n",
    "        try:\n",
    "            t_pred,node_feature = model(data, t_batch)\n",
    "            h_pred,_ = model(data, h_batch)\n",
    "            emb = h_pred.reshape(-1).detach().numpy()\n",
    "        except:\n",
    "            print(f\"Some Error in model - Check once file no {ind} and drug {i}\")\n",
    "            t_pred = np.zeros((2,3))\n",
    "            h_pred = np.zeros((2,3))\n",
    "            drug_df = pd.concat([pd.DataFrame(t_pred),pd.DataFrame(h_pred)],axis=1)\n",
    "            emb = np.array(drug_df).reshape(-1)\n",
    "        embeddings.append(emb)\n",
    "    embeddings = np.array(embeddings).reshape(-1).tolist()\n",
    "    drug_embeddings.append(embeddings)\n",
    "    drugs.append([i])\n",
    "    log_memory_usage(f\"After processing drug {ind}\")\n",
    "\n",
    "    # Clear unnecessary variables and collect garbage\n",
    "    del edge_lists, embeddings, data, test_loader, sampler\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"----1st for \")\n",
    "def pad(drug_embeddings):\n",
    "    padding = max(len(embedding) for embedding in drug_embeddings)\n",
    "    padded_embeddings = []\n",
    "    for embedding in drug_embeddings:\n",
    "        padded_embedding = np.pad(embedding, (0, padding - len(embedding)), 'constant')\n",
    "        padded_embeddings.append(padded_embedding.tolist()) \n",
    "        del padded_embedding\n",
    "    return padded_embeddings\n",
    "\n",
    "\n",
    "\n",
    "padded_embeddings =  pad(drug_embeddings)\n",
    "print(\"----2nd for \")\n",
    "padding = max(len(embedding) for embedding in drug_embeddings)\n",
    "embedding_drug_set = {}\n",
    "for i in range(len(drugs)):\n",
    "    embedding_drug_set[drugs[i][0]] = padded_embeddings[i]\n",
    "\n",
    "\n",
    "with open('embedding_drug_set.json', 'w') as json_file:\n",
    "    json.dump(embedding_drug_set, json_file)\n",
    "\n",
    "\n",
    "\n",
    "print(\"----Saving \")\n",
    "benchmark = pd.DataFrame([drugs,padded_embeddings,mrr,hits10,[padding]]).T\n",
    "benchmark.columns = [\"Drugs\", \"Drug Embeddings\",\"mrr\",\"hits@10\",\"padding\"]\n",
    "benchmark.to_csv(\"results.csv\",index=False)\n",
    "\n",
    "drug_embeddings_str = [json.dumps(embedding) for embedding in padded_embeddings]\n",
    "\n",
    "benchmark = pd.DataFrame({'Drugs': drugs, 'Drug Embeddings': drug_embeddings_str, 'mrr': mrr, 'hits@10': hits10})\n",
    "benchmark.to_csv(\"results1.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "def sort_runs(run_strings):\n",
    "    # Extract numerical part, convert to int, and sort\n",
    "    numbers = sorted(int(run[4:]) for run in run_strings)\n",
    "    return numbers\n",
    "\n",
    "# Example usage\n",
    "run_strings = [\"runs3\", \"runs1\", \"runs2\"]\n",
    "sorted_numbers = sort_runs(run_strings)\n",
    "print(sorted_numbers[-1]+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   precision_0  precision_1  precision_accuracy  precision_macro avg  \\\n",
      "0          0.5          0.5                 0.5                  0.5   \n",
      "\n",
      "   precision_weighted avg  recall_0  recall_1  recall_accuracy  \\\n",
      "0                     0.5       0.5       0.5              0.5   \n",
      "\n",
      "   recall_macro avg  recall_weighted avg  f1-score_0  f1-score_1  \\\n",
      "0               0.5                  0.5         0.5         0.5   \n",
      "\n",
      "   f1-score_accuracy  f1-score_macro avg  f1-score_weighted avg  support_0  \\\n",
      "0                0.5                 0.5                    0.5        2.0   \n",
      "\n",
      "   support_1  support_accuracy  support_macro avg  support_weighted avg  \n",
      "0        2.0               0.5                4.0                   4.0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_accuracy</th>\n",
       "      <th>precision_macro avg</th>\n",
       "      <th>precision_weighted avg</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_accuracy</th>\n",
       "      <th>recall_macro avg</th>\n",
       "      <th>recall_weighted avg</th>\n",
       "      <th>f1-score_0</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_accuracy</th>\n",
       "      <th>f1-score_macro avg</th>\n",
       "      <th>f1-score_weighted avg</th>\n",
       "      <th>support_0</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_accuracy</th>\n",
       "      <th>support_macro avg</th>\n",
       "      <th>support_weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision_0  precision_1  precision_accuracy  precision_macro avg  \\\n",
       "0          0.5          0.5                 0.5                  0.5   \n",
       "\n",
       "   precision_weighted avg  recall_0  recall_1  recall_accuracy  \\\n",
       "0                     0.5       0.5       0.5              0.5   \n",
       "\n",
       "   recall_macro avg  recall_weighted avg  f1-score_0  f1-score_1  \\\n",
       "0               0.5                  0.5         0.5         0.5   \n",
       "\n",
       "   f1-score_accuracy  f1-score_macro avg  f1-score_weighted avg  support_0  \\\n",
       "0                0.5                 0.5                    0.5        2.0   \n",
       "\n",
       "   support_1  support_accuracy  support_macro avg  support_weighted avg  \n",
       "0        2.0               0.5                4.0                   4.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class TrainingMetrics:\n",
    "    def get_training_metrics(self, loss, report):\n",
    "        \"\"\"\n",
    "        Parses the training report and loss to generate a linear pandas DataFrame with training metrics.\n",
    "\n",
    "        Parameters:\n",
    "        - loss: The training loss (assumed to be a float or a list of loss values).\n",
    "        - report: The training report containing metrics (assumed to be a dictionary).\n",
    "\n",
    "        Returns:\n",
    "        - A pandas DataFrame with the parsed training metrics.\n",
    "        \"\"\"\n",
    "        # Step 1: Parse the loss (assuming it's a single value or a list of values)\n",
    "        if isinstance(loss, list):\n",
    "            avg_loss = sum(loss) / len(loss)\n",
    "        else:\n",
    "            avg_loss = loss\n",
    "\n",
    "        # Step 2: Parse the report (assuming it's a dictionary)\n",
    "        if isinstance(report, dict):\n",
    "            metrics = report\n",
    "        else:\n",
    "            raise ValueError(\"Report should be a dictionary\")\n",
    "\n",
    "        # Step 3: Convert metrics to a pandas DataFrame\n",
    "        df = pd.DataFrame(metrics).transpose()\n",
    "\n",
    "\n",
    "\n",
    "        # Step 5: Flatten the DataFrame\n",
    "        df_flat = df.unstack().to_frame().T\n",
    "        df_flat.columns = [f'{col[0]}_{col[1]}' for col in df_flat.columns]\n",
    "\n",
    "        return df_flat\n",
    "\n",
    "# Example usage\n",
    "y_true = [0, 1, 1, 0]\n",
    "y_pred = [0, 0, 1, 1]\n",
    "\n",
    "loss = 0.5\n",
    "report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "tm = TrainingMetrics()\n",
    "metrics_df = tm.get_training_metrics(loss, report_dict)\n",
    "print(metrics_df)\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dataset in module torch_geometric.data.dataset:\n",
      "\n",
      "class Dataset(torch.utils.data.dataset.Dataset)\n",
      " |  Dataset(root: Optional[str] = None, transform: Optional[Callable] = None, pre_transform: Optional[Callable] = None, pre_filter: Optional[Callable] = None, log: bool = True, force_reload: bool = False) -> None\n",
      " |  \n",
      " |  Dataset base class for creating graph datasets.\n",
      " |  See `here <https://pytorch-geometric.readthedocs.io/en/latest/tutorial/\n",
      " |  create_dataset.html>`__ for the accompanying tutorial.\n",
      " |  \n",
      " |  Args:\n",
      " |      root (str, optional): Root directory where the dataset should be saved.\n",
      " |          (optional: :obj:`None`)\n",
      " |      transform (callable, optional): A function/transform that takes in a\n",
      " |          :class:`~torch_geometric.data.Data` or\n",
      " |          :class:`~torch_geometric.data.HeteroData` object and returns a\n",
      " |          transformed version.\n",
      " |          The data object will be transformed before every access.\n",
      " |          (default: :obj:`None`)\n",
      " |      pre_transform (callable, optional): A function/transform that takes in\n",
      " |          a :class:`~torch_geometric.data.Data` or\n",
      " |          :class:`~torch_geometric.data.HeteroData` object and returns a\n",
      " |          transformed version.\n",
      " |          The data object will be transformed before being saved to disk.\n",
      " |          (default: :obj:`None`)\n",
      " |      pre_filter (callable, optional): A function that takes in a\n",
      " |          :class:`~torch_geometric.data.Data` or\n",
      " |          :class:`~torch_geometric.data.HeteroData` object and returns a\n",
      " |          boolean value, indicating whether the data object should be\n",
      " |          included in the final dataset. (default: :obj:`None`)\n",
      " |      log (bool, optional): Whether to print any console output while\n",
      " |          downloading and processing the dataset. (default: :obj:`True`)\n",
      " |      force_reload (bool, optional): Whether to re-process the dataset.\n",
      " |          (default: :obj:`False`)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dataset\n",
      " |      torch.utils.data.dataset.Dataset\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, idx: Union[int, numpy.integer, slice, torch.Tensor, numpy.ndarray, collections.abc.Sequence]) -> Union[ForwardRef('Dataset'), torch_geometric.data.data.BaseData]\n",
      " |      In case :obj:`idx` is of type integer, will return the data object\n",
      " |      at index :obj:`idx` (and transforms it in case :obj:`transform` is\n",
      " |      present).\n",
      " |      In case :obj:`idx` is a slicing object, *e.g.*, :obj:`[2:5]`, a list, a\n",
      " |      tuple, or a :obj:`torch.Tensor` or :obj:`np.ndarray` of type long or\n",
      " |      bool, will return a subset of the dataset at the specified indices.\n",
      " |  \n",
      " |  __init__(self, root: Optional[str] = None, transform: Optional[Callable] = None, pre_transform: Optional[Callable] = None, pre_filter: Optional[Callable] = None, log: bool = True, force_reload: bool = False) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self) -> Iterator[torch_geometric.data.data.BaseData]\n",
      " |  \n",
      " |  __len__(self) -> int\n",
      " |      The number of examples in the dataset.\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  download(self) -> None\n",
      " |      Downloads the dataset to the :obj:`self.raw_dir` folder.\n",
      " |  \n",
      " |  get(self, idx: int) -> torch_geometric.data.data.BaseData\n",
      " |      Gets the data object at index :obj:`idx`.\n",
      " |  \n",
      " |  get_summary(self) -> Any\n",
      " |      Collects summary statistics for the dataset.\n",
      " |  \n",
      " |  index_select(self, idx: Union[slice, torch.Tensor, numpy.ndarray, collections.abc.Sequence]) -> 'Dataset'\n",
      " |      Creates a subset of the dataset from specified indices :obj:`idx`.\n",
      " |      Indices :obj:`idx` can be a slicing object, *e.g.*, :obj:`[2:5]`, a\n",
      " |      list, a tuple, or a :obj:`torch.Tensor` or :obj:`np.ndarray` of type\n",
      " |      long or bool.\n",
      " |  \n",
      " |  indices(self) -> collections.abc.Sequence\n",
      " |  \n",
      " |  len(self) -> int\n",
      " |      Returns the number of data objects stored in the dataset.\n",
      " |  \n",
      " |  print_summary(self) -> None\n",
      " |      Prints summary statistics of the dataset to the console.\n",
      " |  \n",
      " |  process(self) -> None\n",
      " |      Processes the dataset to the :obj:`self.processed_dir` folder.\n",
      " |  \n",
      " |  shuffle(self, return_perm: bool = False) -> Union[ForwardRef('Dataset'), Tuple[ForwardRef('Dataset'), torch.Tensor]]\n",
      " |      Randomly shuffles the examples in the dataset.\n",
      " |      \n",
      " |      Args:\n",
      " |          return_perm (bool, optional): If set to :obj:`True`, will also\n",
      " |              return the random permutation used to shuffle the dataset.\n",
      " |              (default: :obj:`False`)\n",
      " |  \n",
      " |  to_datapipe(self) -> Any\n",
      " |      Converts the dataset into a :class:`torch.utils.data.DataPipe`.\n",
      " |      \n",
      " |      The returned instance can then be used with :pyg:`PyG's` built-in\n",
      " |      :class:`DataPipes` for baching graphs as follows:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          from torch_geometric.datasets import QM9\n",
      " |      \n",
      " |          dp = QM9(root='./data/QM9/').to_datapipe()\n",
      " |          dp = dp.batch_graphs(batch_size=2, drop_last=True)\n",
      " |      \n",
      " |          for batch in dp:\n",
      " |              pass\n",
      " |      \n",
      " |      See the `PyTorch tutorial\n",
      " |      <https://pytorch.org/data/main/tutorial.html>`_ for further background\n",
      " |      on DataPipes.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  has_download\n",
      " |      Checks whether the dataset defines a :meth:`download` method.\n",
      " |  \n",
      " |  has_process\n",
      " |      Checks whether the dataset defines a :meth:`process` method.\n",
      " |  \n",
      " |  num_classes\n",
      " |      Returns the number of classes in the dataset.\n",
      " |  \n",
      " |  num_edge_features\n",
      " |      Returns the number of features per edge in the dataset.\n",
      " |  \n",
      " |  num_features\n",
      " |      Returns the number of features per node in the dataset.\n",
      " |      Alias for :py:attr:`~num_node_features`.\n",
      " |  \n",
      " |  num_node_features\n",
      " |      Returns the number of features per node in the dataset.\n",
      " |  \n",
      " |  processed_dir\n",
      " |  \n",
      " |  processed_file_names\n",
      " |      The name of the files in the :obj:`self.processed_dir` folder that\n",
      " |      must be present in order to skip processing.\n",
      " |  \n",
      " |  processed_paths\n",
      " |      The absolute filepaths that must be present in order to skip\n",
      " |      processing.\n",
      " |  \n",
      " |  raw_dir\n",
      " |  \n",
      " |  raw_file_names\n",
      " |      The name of the files in the :obj:`self.raw_dir` folder that must\n",
      " |      be present in order to skip downloading.\n",
      " |  \n",
      " |  raw_paths\n",
      " |      The absolute filepaths that must be present in order to skip\n",
      " |      downloading.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  __parameters__ = ()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in loader:\n",
    "    sample = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DrugPairBatch(identifiers=           drug_1    drug_2     context  label\n",
       "45054     3034010     60838       KBM-7    1.0\n",
       "88400        2123      2141      HOP-62    0.0\n",
       "172321   24776445  11525740    NCI-H226    1.0\n",
       "82025      248862  24197464        EKVX    0.0\n",
       "32015        8226  54680692       KBM-7    0.0\n",
       "158504   42611257      3950      SF-295    1.0\n",
       "81496       77082    123608      MOLT-4    0.0\n",
       "33571     5284592      5426       KBM-7    0.0\n",
       "47627       41684      3019       KBM-7    0.0\n",
       "67608    54608520      2907       K-562    0.0\n",
       "138921    3081361  25126798   SK-MEL-28    1.0\n",
       "187840    5352062     32874      OVCAR3    0.0\n",
       "142414  135398738    457193     OVCAR-5    1.0\n",
       "82701     2733525    248862      SW-620    0.0\n",
       "18204        5394  46239015      SW-620    0.0\n",
       "111892     356653      5426      HOP-92    0.0\n",
       "179063   25126798    216326    CCRF-CEM    0.0\n",
       "151778      71384      2578       UO-31    0.0\n",
       "98597        2187      5746      OVCAR3    0.0\n",
       "131424     123631    208908    CCRF-CEM    1.0\n",
       "166678     132971    356653      IGROV1    0.0\n",
       "30960        3373     51634       KBM-7    0.0\n",
       "139362  135410875      5291  MDA-MB-435    0.0\n",
       "35230        7697      4173       KBM-7    0.0, drug_features_left=tensor([[0., 3., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.]]), drug_molecules_left=PackedGraph(batch_size=24, num_nodes=[35, 15, 27, ..., 22, 31, 13], num_edges=[70, 30, 58, ..., 48, 66, 26], num_relation=4), drug_features_right=tensor([[0., 0., 1.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 2.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.]]), drug_molecules_right=PackedGraph(batch_size=24, num_nodes=[43, 12, 32, ..., 15, 37, 12], num_edges=[98, 22, 68, ..., 30, 82, 24], num_relation=4), context_features=tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), labels=tensor([[1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "class UltraNet(nn.Module):\n",
    "\n",
    "    def __init__(self,input_dims):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dims\n",
    "        self.lin1 = nn.Linear(in_features=self.input_dim,out_features=32)\n",
    "\n",
    "    \n",
    "\n",
    "    def get_embeddings(self,molecules):\n",
    "        drug_embedding_batch = []\n",
    "        for i in molecules:\n",
    "            edge_lists = []\n",
    "            for j in i.edge_list.cpu().numpy().tolist():\n",
    "                x1 = [j[0],j[2],j[1]]\n",
    "                edge_lists.append(j)\n",
    "            \n",
    "            embeddings  = []\n",
    "  \n",
    "            md = MoleculesData()\n",
    "            data = md.process()\n",
    "            device = util.get_devices(None)\n",
    "            world_size = util.get_world_size()\n",
    "            rank = util.get_rank()\n",
    "            sampler = torch_data.DistributedSampler(edge_lists, world_size, rank)\n",
    "            test_loader = torch_data.DataLoader(edge_lists, len(edge_lists), sampler=sampler)    \n",
    "            model.eval()\n",
    "            for batch in test_loader:\n",
    "                t_batch, h_batch = all_negative(data, batch)\n",
    "                try:\n",
    "                    t_pred,node_feature = model(data, t_batch)\n",
    "                    h_pred,_ = model(data, h_batch)\n",
    "                    emb = h_pred.reshape(-1).detach().numpy()\n",
    "                except:\n",
    "                    print(f\"Some Error in model - Check once file no {ind} and drug {i}\")\n",
    "                    t_pred = np.zeros((2,3))\n",
    "                    h_pred = np.zeros((2,3))\n",
    "                    drug_df = pd.concat([pd.DataFrame(t_pred),pd.DataFrame(h_pred)],axis=1)\n",
    "                    emb = np.array(drug_df).reshape(-1)\n",
    "                embeddings.append(emb)\n",
    "            drug_embedding_batch.append(embeddings)\n",
    "        return torch.tensor(drug_embedding_batch,dtype=torch.float32)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self,  molecules_left: PackedGraph, molecules_right: PackedGraph, plot=False,\n",
    "    ) -> torch.FloatTensor:\n",
    "            \n",
    "        drug_embedding_left = self.get_embeddings(molecules_left)\n",
    "        x = self.lin1(drug_embedding_left)\n",
    "\n",
    "        return drug_embedding_left\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UltraNet(input_dims=48980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_node=35, num_edge=70, num_relation=4)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.drug_molecules_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug_1</th>\n",
       "      <th>drug_2</th>\n",
       "      <th>context</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45054</th>\n",
       "      <td>3034010</td>\n",
       "      <td>60838</td>\n",
       "      <td>KBM-7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88400</th>\n",
       "      <td>2123</td>\n",
       "      <td>2141</td>\n",
       "      <td>HOP-62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172321</th>\n",
       "      <td>24776445</td>\n",
       "      <td>11525740</td>\n",
       "      <td>NCI-H226</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82025</th>\n",
       "      <td>248862</td>\n",
       "      <td>24197464</td>\n",
       "      <td>EKVX</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32015</th>\n",
       "      <td>8226</td>\n",
       "      <td>54680692</td>\n",
       "      <td>KBM-7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158504</th>\n",
       "      <td>42611257</td>\n",
       "      <td>3950</td>\n",
       "      <td>SF-295</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81496</th>\n",
       "      <td>77082</td>\n",
       "      <td>123608</td>\n",
       "      <td>MOLT-4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33571</th>\n",
       "      <td>5284592</td>\n",
       "      <td>5426</td>\n",
       "      <td>KBM-7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47627</th>\n",
       "      <td>41684</td>\n",
       "      <td>3019</td>\n",
       "      <td>KBM-7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67608</th>\n",
       "      <td>54608520</td>\n",
       "      <td>2907</td>\n",
       "      <td>K-562</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138921</th>\n",
       "      <td>3081361</td>\n",
       "      <td>25126798</td>\n",
       "      <td>SK-MEL-28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187840</th>\n",
       "      <td>5352062</td>\n",
       "      <td>32874</td>\n",
       "      <td>OVCAR3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142414</th>\n",
       "      <td>135398738</td>\n",
       "      <td>457193</td>\n",
       "      <td>OVCAR-5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82701</th>\n",
       "      <td>2733525</td>\n",
       "      <td>248862</td>\n",
       "      <td>SW-620</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18204</th>\n",
       "      <td>5394</td>\n",
       "      <td>46239015</td>\n",
       "      <td>SW-620</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111892</th>\n",
       "      <td>356653</td>\n",
       "      <td>5426</td>\n",
       "      <td>HOP-92</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179063</th>\n",
       "      <td>25126798</td>\n",
       "      <td>216326</td>\n",
       "      <td>CCRF-CEM</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151778</th>\n",
       "      <td>71384</td>\n",
       "      <td>2578</td>\n",
       "      <td>UO-31</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98597</th>\n",
       "      <td>2187</td>\n",
       "      <td>5746</td>\n",
       "      <td>OVCAR3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131424</th>\n",
       "      <td>123631</td>\n",
       "      <td>208908</td>\n",
       "      <td>CCRF-CEM</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166678</th>\n",
       "      <td>132971</td>\n",
       "      <td>356653</td>\n",
       "      <td>IGROV1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30960</th>\n",
       "      <td>3373</td>\n",
       "      <td>51634</td>\n",
       "      <td>KBM-7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139362</th>\n",
       "      <td>135410875</td>\n",
       "      <td>5291</td>\n",
       "      <td>MDA-MB-435</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35230</th>\n",
       "      <td>7697</td>\n",
       "      <td>4173</td>\n",
       "      <td>KBM-7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           drug_1    drug_2     context  label\n",
       "45054     3034010     60838       KBM-7    1.0\n",
       "88400        2123      2141      HOP-62    0.0\n",
       "172321   24776445  11525740    NCI-H226    1.0\n",
       "82025      248862  24197464        EKVX    0.0\n",
       "32015        8226  54680692       KBM-7    0.0\n",
       "158504   42611257      3950      SF-295    1.0\n",
       "81496       77082    123608      MOLT-4    0.0\n",
       "33571     5284592      5426       KBM-7    0.0\n",
       "47627       41684      3019       KBM-7    0.0\n",
       "67608    54608520      2907       K-562    0.0\n",
       "138921    3081361  25126798   SK-MEL-28    1.0\n",
       "187840    5352062     32874      OVCAR3    0.0\n",
       "142414  135398738    457193     OVCAR-5    1.0\n",
       "82701     2733525    248862      SW-620    0.0\n",
       "18204        5394  46239015      SW-620    0.0\n",
       "111892     356653      5426      HOP-92    0.0\n",
       "179063   25126798    216326    CCRF-CEM    0.0\n",
       "151778      71384      2578       UO-31    0.0\n",
       "98597        2187      5746      OVCAR3    0.0\n",
       "131424     123631    208908    CCRF-CEM    1.0\n",
       "166678     132971    356653      IGROV1    0.0\n",
       "30960        3373     51634       KBM-7    0.0\n",
       "139362  135410875      5291  MDA-MB-435    0.0\n",
       "35230        7697      4173       KBM-7    0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MoleculesData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrug_molecules_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrug_molecules_right\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/capstone/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/capstone/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[52], line 23\u001b[0m, in \u001b[0;36mUltraNet.forward\u001b[0;34m(self, molecules_left, molecules_right, plot)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,  molecules_left: PackedGraph, molecules_right: PackedGraph, plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[0;32m---> 23\u001b[0m     drug_embedding_left \u001b[38;5;241m=\u001b[39m \u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmolecules_left\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin1(drug_embedding_left)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m drug_embedding_left\n",
      "Cell \u001b[0;32mIn[51], line 11\u001b[0m, in \u001b[0;36mget_embeddings\u001b[0;34m(molecules)\u001b[0m\n\u001b[1;32m      7\u001b[0m     edge_lists\u001b[38;5;241m.\u001b[39mappend(j)\n\u001b[1;32m      9\u001b[0m embeddings  \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 11\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[43mMoleculesData\u001b[49m()\n\u001b[1;32m     12\u001b[0m data \u001b[38;5;241m=\u001b[39m md\u001b[38;5;241m.\u001b[39mprocess()\n\u001b[1;32m     15\u001b[0m device \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mget_devices(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MoleculesData' is not defined"
     ]
    }
   ],
   "source": [
    "model(sample.drug_molecules_left, sample.drug_molecules_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DrugPairBatch(identifiers=           drug_1    drug_2     context  label\n",
       "45054     3034010     60838       KBM-7    1.0\n",
       "88400        2123      2141      HOP-62    0.0\n",
       "172321   24776445  11525740    NCI-H226    1.0\n",
       "82025      248862  24197464        EKVX    0.0\n",
       "32015        8226  54680692       KBM-7    0.0\n",
       "158504   42611257      3950      SF-295    1.0\n",
       "81496       77082    123608      MOLT-4    0.0\n",
       "33571     5284592      5426       KBM-7    0.0\n",
       "47627       41684      3019       KBM-7    0.0\n",
       "67608    54608520      2907       K-562    0.0\n",
       "138921    3081361  25126798   SK-MEL-28    1.0\n",
       "187840    5352062     32874      OVCAR3    0.0\n",
       "142414  135398738    457193     OVCAR-5    1.0\n",
       "82701     2733525    248862      SW-620    0.0\n",
       "18204        5394  46239015      SW-620    0.0\n",
       "111892     356653      5426      HOP-92    0.0\n",
       "179063   25126798    216326    CCRF-CEM    0.0\n",
       "151778      71384      2578       UO-31    0.0\n",
       "98597        2187      5746      OVCAR3    0.0\n",
       "131424     123631    208908    CCRF-CEM    1.0\n",
       "166678     132971    356653      IGROV1    0.0\n",
       "30960        3373     51634       KBM-7    0.0\n",
       "139362  135410875      5291  MDA-MB-435    0.0\n",
       "35230        7697      4173       KBM-7    0.0, drug_features_left=tensor([[0., 3., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.]]), drug_molecules_left=PackedGraph(batch_size=24, num_nodes=[35, 15, 27, ..., 22, 31, 13], num_edges=[70, 30, 58, ..., 48, 66, 26], num_relation=4), drug_features_right=tensor([[0., 0., 1.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 2.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.]]), drug_molecules_right=PackedGraph(batch_size=24, num_nodes=[43, 12, 32, ..., 15, 37, 12], num_edges=[98, 22, 68, ..., 30, 82, 24], num_relation=4), context_features=tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), labels=tensor([[1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
